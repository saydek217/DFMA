# Dual-Focus Multiscale Attention (DFMA) for Real-Time Object Detection in Mixed Reality

This repository contains the official implementation of **DFMA** â€” a lightweight dual-path attention module (multi-scale **spatial** + **channel**) that plugs into Ultralytics YOLO (v8+ family) to boost accuracy on hard, low-textured, look-alike objects **while preserving real-time performance**. The method was presented at **IEEE ISMAR 2025**.

> TL;DR: Dropâ€in DFMA blocks + ready YAML + scripts to reproduce training.

---

## âœ¨ Features

- Plug-and-play **DFMA** (and optional **MSAF** (Multi-Scale Attention Fusion)) layers for YOLO backbones/FPN.
- **Ultralytics-native YAML** (`dfma.yaml`) for painless integration.
- **Python API** and optional CLI; simple training code.

---

## ğŸ“… Roadmap & Availability

- **Data generation code (Blender + hybrid backgrounds):** _coming soon_  
- **Unity (Sentis) MR demo (scene + scripts):** _coming soon_  
- **Paper (ISMAR 2025):** _link coming soon_

> Watch the repository for releases and updates:
> - â­ **Star** the repo to bookmark it
> - ğŸ‘€ **Watch** â†’ â€œReleases onlyâ€ to get notified when we publish code & the paper link

---

## ğŸ”— Paper Link (placeholder)

**Title:** Dual-Focus Multiscale Attention for Object Detection in Mixed Reality (ISMAR 2025)  
**PDF/DOI:** _coming soon_


## ğŸ“£ Changelog

- **v0.1.0** â€” Initial public codebase (DFMA modules, config, registry, tests).  
- **Next** â€” Add data-generation scripts and Unity demo; publish paper link.
